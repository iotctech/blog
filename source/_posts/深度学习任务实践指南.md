---
title: 深度学习任务实践指南
date: 2020-07-16 11:21:22
tags:
 - 深度学习
 - NLP
 - 任务拆分
 - 技术选型
 - 训练效率
categories:
 - [deeplearning]
---

### 1、业务任务拆分
我们实际中面对的业务任务往往比较抽象，比如问答系统、对话系统等，如果针对问题直接解决问题，往往会导致时间、算力等成本的浪费。在深度学习模型0-1的阶段，我们的目标往往是快速搭建一个demo，确定优化方向。所以针对复杂的任务，我们需要将其抽象为已得到很好解决的典型问题，利用典型问题的预训练模型，快速搭建我们的业务base模型。

#### 1.1、拆分依据
- 明确输入与输出
- 熟知典型问题
- 适当拆分

#### 1.2、典型任务（NLP为例）

**文本分类**

- 输入文本用X表示，输出标签用Y表示
- 如果Y表示某一类的概率，或者各个类的概率分布，则可以抽象为文本分类问题。如情感分类任务、新闻主题分类任务、文本蕴含任务等。

**文本匹配**

- 输入文本用X表示，输出标签用Y表示
- 如果X是2段文本(X1, X2)，Y表示二者的相似度，可抽象为文本匹配问题。如语义相似度、相似问题匹配等任务。

*PS：文本聚类的问题可以通过文本相似度问题进行处理*

**序列标注**

- 输入文本用X表示，输出标签用Y表示
- 如果X为一段文本序列，Y是一个与X等长的序列，可抽象为序列标注问题。如命名实体识别。

*PS：分词、词性标注、组块分析、语义角色标注、词槽挖掘都是典型的序列标注任务。阅读理解可以理解为特殊的序列标注，X是2段文本(X1, X2)，分别表示整篇文章和问题，Y是篇章中的一小段文本，表示对应问题的答案。*

**文本生成**

- 输入文本用X表示，输出标签用Y表示
- 如果X是一段文本序列，Y是一个不定长的文本，可抽象为文本生成问题。如机器翻译、文本摘要、标题生成、闲聊等任务。

*一个不太严谨的分类*

| 文本分类 | 文本匹配 | 序列标注 | 文本生成 |
|------|------|------|------|
| 情感分类 | 问答匹配 | 信息抽取 | 机器翻译 |
| 文本审核 | 新闻聚类 | 词性标注 | 摘要生成 |
| 意图识别 | querry匹配 | 词槽填充 | 标题生成 |

#### 1.3、抽象与拆分任务取舍经验
**复杂任务先拆分先化简**

例如：
**问答系统 = 实体链指 + 关系分类 + 逻辑表达式 + 问答匹配**
**对话系统 = 意图理解 + 聊天任务 + 问答任务 + 对话管理**

**优先推荐有监督学习的深度学习任务**

在任务选择上：
**有监督** 优于 **无监督**
**深度学习** 优于 **非深度学习**

例如：
文本关键词抽取：可以用TF IDF之类的无监督算法，但效果控制较困难，不如转换为文本分类问题，更可控。
文本聚类问题： 可以用LDA之类的算法，但效果不够好，不如转换为深度学习文本匹配问题，效果更好，并可不断改进。

### 2、如何进行技术选型
#### 2.1、明确业务目标与限制条件
| 目标与限制 | 典型指标 | 说明 |
|------|------|------|
| 预测部署性能 | 单机QPS | CPU/GPU不同 |
| 模型效果 | 分类：准确率、精确率、召回率、宏平均、微平均等 | 评估指标应在训练之前基本确定，否则很容易训偏 |
| 数据大小限制 | 有标注样本数 | 一般标注成本较高 |
| 训练时间成本 | 每一轮训练所需要的时间 | 与硬件条件、GPU利用率相关 |
| 硬件采购成本 | 价格、租金 | 训练与预测部署不同 |
| 开发迭代成本 | 从0到1的时间，从1到2的时间 | 非常耗时、学习时间也是成本 |

例如：

| 目标与限制 | 以搜索问答为例 |
|------|------|
| 预测部署性能 | CPU单机QPS：1000+ |
| 模型效果 | 分类+匹配：保证精确率前提下的召回率 |
| 数据大小限制 | 人工标注样本：10万+ |
| 训练时间成本 | 每一轮训练所需时间：1天之内 |
| 硬件采购成本 | 基于已有GPU训练平台，不新增采购 |
| 开发迭代成本 | 从1到2：一个月之内 |

#### 2.2、可以进行哪些选择
| 技术选项 | 说明 |
|------|------|
| 开发工具 | 一站式训练平台、无代码训练工具、训练开发套件、深度学习框架 |
| 训练硬件 | GPU（型号、卡数、节点数），CPU（节点数），本地or集群 |
| 神经网络及其参数 | 预制网络（BOW、CNN、LSTM、CRF、ERNIE），自建网络 |
| 预训练模型 | ERNIE（版本号、BASE、LARGE），领域模型、任务模型、随机初始 |
| 训练数据大小 | 1000+,1万+，10万+，100万+，1千万+，1亿+ |
| 训练数据特征 | 文本特征（多段？）、离散非文本特征、连续数值特征 |

#### 2.3、选择方法
**基于预测部署性能**

例如：搜索问答场景

定性分析：

| 要求 | 选择 |
|------|------|
| qps>1000 | 一般不适合直接应用ERNIE、ERNIE-TINY；可尝试模型蒸馏（模型效果有一定损失）；也可尝试ERNIE-WORD |
| qps>100 | 推荐尝试ERNIE-TINY等轻量级加速版模型；预测用GPU可配置低些以降低成本；GPU加速推断策略正在不断完善 |
| 无强制要求 | 大胆尝试各种预训练模型 |

所以搜索问答场景适合模型蒸馏的技术方案

**基于模型效果**

通常：

**有预训练模型** 优于 **无预训练模型**
**多样特征** 优于 **单一特征**
**ERNIE-LARGE** 优于 **ERNIE-BASE** 优于 **ERNIE-TINY** 优于 **ERNIE-WORD**
**ERNIE新版本** 优于 **ERNIE旧版本**
**垂类模型** 优于 **通用模型**
**大数据** 优于 **小数据**
**标注数据质量** 优于 **标注数据数量**
**复杂网络** 优于 **简单网络**
**多阶段训练** 优于 **单阶段训练**

### 3、如何提升训练效率（怎么用好GPU）
- **大原则**
GPU利用率越高，训练越快。

- **先小后大**
先单机单卡，再单机多卡，最后多级多卡；单机多卡的GPU利用率更高、更快。

- **文件数要大于卡数**
多卡训练时是将不同的数据文件送给不同的卡，所以数据文件的个数要大于卡的个数；数据文件建议拆分细一些，这可以提升数据读取的速度。

- **高级玩法**
熟练的同学可以尝试GPU多进程单机多卡训练，混合精度训练等方法，提升训练速度。

- **train_log_step、eval_step、save_model_step**
分别表示每多少步打印训练日志、每多少步评估一次验证集、每多少步保存一次模型，设置不当也会拖慢训练时间，一般建议三者依次放大十倍，如：10、100、1000

- **batch_size**
设置过小容易收敛慢，设置过大容易超过显存极限直接挂掉；如果使用ERNIE，batch_size建议小一些，使用large版本建议更小一些，如果输入语句并不是很长，可以适当增加batch_size；如果不使用ERNIE，可以大一些；建议使用默认配置，如果想优化可以采用二分查找。

### 4、如何提升迭代效率
#### 4.1、云端开发 VS 本地开发
**如果只想快速训练基线模型验证效果**
- 建议使用EasyDL、BML等云端平台
- 免去前期搭建环境的成本，减少从0到1的开发时间

**如果需要不断调试、迭代优化模型**
- 如果有条件建议本地调试+云端训练的方式，减少从1到2的开发时间
- 本地调试：减少网络传输和任务队列排队的时间
- 云端训练：充分利用云端集群资源
- 工具版本地调试成功后再上集群训练能极大提升迭代效率

#### 4.2、规范的开发流程
**分析业务背景**
- 明确任务输入与输出，将其抽象为已得到很好解决的典型任务，明确评估指标

**快速实现模型基线**
- 准备小数据规模的格式规范的训练数据，进行无代码训练（最快）
- 技术选型非常重要，需选择好网络和预训练模型

**优化模型效果**
- 各优化手段按照投入产出比排序如下：
a、进一步分析你的业务背景和需求，进行更细致的技术选型
b、采用本地工具进行本地小数据调试，极大地提升迭代效率
c、通过配置参数级训练进行自主调参
d、部分代码级训练（自定义组网）训练并进行调参
e、代码级训练进行深度自主开发
f、策略基本稳定后在足量的大数据上进行训练

#### 4.3、开发方式的选择
**无代码训练（不调参）**
- 如：EasyDL经典版、BML预制产线
- 便于快速得到基线效果，无任何调参经验都可使用

**配置参数级训练（自主调参）**
- 如：EasyDL专业版、BML预置产线
- 最好具备3个月调参经验，否则需补充相关知识

**部分代码级训练（自定义组网）**
- 如：EasyDL专业版、BML专业开发套件
- 最好具备6个月调参经验，否则需要补充相关知识

**代码级训练（深度自定义）**
- 如：文心开源版，文心端到端开发套件
- 最好具备6个月调参经验，否则需要补充相关知识

### 5、如何优化模型
#### 5.1、优化数据
**优化数据质量**
- 对于ERNIE系列预训练模型，数据的质量优于数量
- 反复观察badcase，针对典型case增加正确样本
- 可考虑数据降噪相关策略

**增加数据数量**
- 通过学习曲线评估数据数量是否合适
- 在数据集很大的情况下，建议小数据跑一跑
- 可考虑数据增强等相关策略

**增加数据特征**
- 可考虑增加非文本数据特征
- 可以尝试增加新的文本特征，比如N-gram、subword、分词边界、词性、语义组块等特征

#### 5.2、优化调参与组网
**大原则**
- 过拟合则降低复杂度：增加数据量，选用参数较少的模型
- 欠拟合则提升复杂度：选择参数较多的复杂模型
- 通过学习曲线判断是否过拟合

**最常用的参数：学习率**
- 最简单的方式是选用adam等自动调整学习率的优化器
- 如果手动调整学习率，一般按等比数列调整，如每次放大（缩小）10倍/5倍
- ERNIE系列预训练模型对学习率更加敏感，一般建议直接采用预制学习率，如果需要调整，可进行2倍3倍的放缩进行试验

**熟练运用热启动**
- 可通过热启动进行多阶段训练，每一阶段将本阶段实验最好的策略模型保存起来，作为下一阶段迭代的热启动模型，可不断累加算法改进的效果

**优化组网**
- 一般建议先采用ERNIE模型不加下游复杂网络进行训练，之后再改进组网

### 6、附录
#### 6.1、无代码调参训练建议具备的相关知识
- 明确以下概念：有监督学习、标签、特征、训练集、验证集、测试集、逻辑回归、过拟合、欠拟合、激活函数、损失函数、神经网络、学习率、正则化、epoch、batch_size、分词、统计词表。
- 知道回归与分类的区别
- 知道如何通过收敛曲线判断过拟合与欠拟合
- 知道准确率、召回率、精确度、F1值、宏平均、微平均的概念与区别
- 知道为什么训练集、验证集、测试集要保证独立同分布
- 知道什么是神经网络
- 知道什么是迁移学习、什么是预训练模型、什么是finetune、迁移学习的优点是什么
- 参考：周志华《机器学习》前三章

#### 6.2、自定义组网训练建议具备的相关知识
- 前提是已掌握无代码调参建议具备的相关知识
- 明确以下概念：Sigmoid函数公式、softmax函数公式、交叉熵公式、前向传播、反向传播、SGD、Adma、词向量、embedding、dropout、BOW、CNN、RNN、GRU、LSTM、迁移学习等等
- 知道神经网络为什么具有非线性切分能力
- 知道NLP中一维CNN中卷积核大小、卷积核的个数各指代什么，时序最大池化层如何操作
- 知道NLP中CNN与LSTM的区别，各擅长处理哪类文本问题
- 知道为什么BOW模型无法识别词语顺序关系
- 知道为什么会梯度爆炸，以及如何解决
- 参考：花书《深度学习》6-10章，《基于深度学习的自然语言处理》整本