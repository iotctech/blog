---
title: 深度学习常用算子
date: 2020-07-27 17:22:34
tags:
 - 深度学习
 - 常用算子
 - Op
categories:
 - [deeplearning]
---

## 1、TensorFlow常用算子
| 序号 | OP | 描述 |
|------|------|------|
|  1 | Relu                  | 激活算子ReLU(x)=max(0,x) |
|  2 | Relu6                 | 激活算子LeakyRelu(x) = max(max(x, 0), 6) |
|  3 | Shape                 | - |
|  4 | Abs                   | - |
|  5 | Sigmoid               | 激活算子sigmoid(x) = 1. / (1. + exp(x)) |
|  6 | Exp                   | - |
|  7 | Rsqrt                 | Tensor单个元素运算: y = 1 / sqrt{x} |
|  8 | swish_f32             | - |
|  9 | Tanh                  | 激活算子tanh(x)=(exp(x)-exp(-x))/(exp(x)+exp(-x)) |
| 10 | LeakyRelu             | 激活算子LeakyRelu(x) = (x >= 0 ? x : x*negative_slope) |
| 11 | Add                   | 两个Tensor计算: + |
| 12 | RealDiv               | 两个Tensor计算: / |
| 13 | Sub                   | 两个Tensor计算: - |
| 14 | Maximum               | - |
| 15 | Mul                   | 两个Tensor计算: * |
| 16 | FloorDiv              | - |
| 17 | Placeholder           | - |
| 18 | Const                 | - |
| 19 | Transpose             | - |
| 20 | FusedBatchNorm        | - |
| 21 | Conv2D                | - |
| 22 | BiasAdd               | 两个Tensor计算: 用于增加bias操作，通常bias是一维Tensor |
| 23 | MaxPool               | - |
| 24 | DepthwiseConv2dNative | - |
| 25 | Reshape               | Tensor维度变换: 将输入Tensor描述转换为新的shape |
| 26 | AvgPool               | - |
| 27 | SplitV                | - |
| 28 | SquaredDifference     | - |
| 29 | Title                 | Tensor维度变换: 将输入数据在每个维度上复制指定次数来生成输出数据 |
| 30 | Pack                  | Tensor维度变换: Pack算子为TensorFlow原生算子，最新的版本已经改名为：Stack。该算子以指定的轴axis，将一个维度为R的张量数组转变成一个维度为R+1的张量。 |
| 31 | Pad                   | Tensor维度变换: Tensor维度变换 |
| 32 | ResizeBilinear        | - |
| 33 | Mean                  | 只有取均值功能的滑窗算子 |
| 34 | MatMul                | 两个Tensor计算: 矩阵乘 |
| 35 | ArgMax                | - |
| 36 | StridedSlice          | - |
| 37 | Slice                 | - |
| 38 | Sum                   | - |
| 39 | Max                   | - |
| 40 | Conv2DBackpropInput   | - |
| 41 | Cast                  | - |
| 42 | Split                 | - |
| 43 | Squeeze               | - |
| 44 | ResizeNearestNeighbor | - |
| 45 | Softmax               | 分类: 通常作为分类网络的最后一层，输出每类的概率 |
| 46 | Range                 | - |
| 47 | ConcatV2              | - |
| 48 | MirrorPad             | - |
| 49 | Identity              | - |
| 50 | GreaterEqual          | - |
| 51 | StopGradient          | - |
| 52 | Minimum               | - |
| 53 | RadnomUniform         | - |
| 54 | Fill                  | - |
| 55 | Floor                 | - |
| 56 | DepthToSpace          | - |


## 2、Caffe常用算子
| 序号 | OP | 描述 |
|------|------|------|
|  1 | Input                | - |
|  2 | Convolution          | 分区域进行特征值提取 |
|  3 | Deconvolution        | 将一个低维度的空间映射到高维度，同时保持他们之间的连接关系/模式 |
|  4 | Pooling              | - |
|  5 | LRN                  | 归一化: Local Response Normalization，即局部响应归一化层 |
|  6 | InnerProduct         | - |
|  7 | Softmax              | - |
|  8 | Slice                | - |
|  9 | Concat               | 实现多个算子的拼接 |
| 10 | PReLU                | - |
| 11 | Accuracy             | - |
| 12 | Eltwise              | 多个Tensor计算: 多个Tensor对应位置元素进行相乘、相加、取最大值中一种操作 |
| 13 | BatchNorm            | 归一化: 加快神经网络的训练收敛速度 |
| 14 | Scale                | Tensor单个元素运算: y(x)=scale*x+bias |
| 15 | Reshape              | - |
| 16 | ArgMax               | - |
| 17 | Crop                 | - |
| 18 | Flatten              | - |
| 19 | Power                | Tensor单个元素运算: f(x)= (scale * x + shift) ^ power |
| 20 | Reduction            | - |
| 21 | Axpy                 | 两个Tensor计算: 向量求和，公式y += a * x |
| 22 | ROIPolling           | 对ROI进行pooling操作，从不同大小的方框得到固定大小相应的feature maps |
| 23 | Permute              | 调整Tensor的输入维度顺序 |
| 24 | DetectionOutput      | - |
| 25 | Normalize            | - |
| 26 | Select               | - |
| 27 | ShuffleChannel       | 调整C维的排序 |
| 28 | ConvolutionDepthwise | - |
| 29 | ReLU                 | - |
| 30 | AbsVal               | Tensor单个元素运算: y(x)=|x| |
| 31 | Sigmoid              | - |
| 32 | TanH                 | - |


## 3、ONNX常用算子
| 序号 | OP | 描述 |
|------|------|------|
|  1 | Relu               | - |
|  2 | LeakyRelu          | - |
|  3 | Elu                | - |
|  4 | ThresholdedRelu    | - |
|  5 | Prelu              | - |
|  6 | Tanh               | - |
|  7 | Shrink             | - |
|  8 | Sigmoid            | - |
|  9 | Pow                | - |
| 10 | Softplus           | - |
| 11 | Softsign           | - |
| 12 | HardSigmoid        | - |
| 13 | Exp                | - |
| 14 | Add                | - |
| 15 | Div                | - |
| 16 | Sub                | - |
| 17 | Mul                | - |
| 18 | Shape              | - |
| 19 | Clip               | - |
| 20 | AveragePool        | - |
| 21 | Sqrt               | - |
| 22 | ReduceSum          | - |
| 23 | ReduceMin          | - |
| 24 | ReduceMean         | - |
| 25 | Constant           | - |
| 26 | Pad                | - |
| 27 | Unsqueeze          | - |
| 28 | Resize             | - |
| 29 | Upsample           | - |
| 30 | Expand             | - |
| 31 | Gather             | - |
| 32 | Slice              | - |
| 33 | Cast               | - |
| 34 | Split              | - |
| 35 | Reshape            | - |
| 36 | ConstantOfShape    | - |
| 37 | Ceil               | - |
| 38 | Concat             | 实现多个算子的拼接 |
| 39 | Flatten            | 将输入tensor中从start_axis维度到end_axis维度合并为1维 |
| 40 | ConvTranspose      | - |
| 41 | MatMul             | - |
| 42 | Sum                | - |
| 43 | Transpose          | - |
| 44 | BatchNormalization | - |
| 45 | Squeeze            | - |
| 46 | Equal              | - |
| 47 | Identity           | - |
| 48 | GlobalAveragePool  | - |
| 49 | MaxPool            | - |
| 50 | Conv               | - |
| 51 | Gemm               | - |
| 52 | NonZero            | - |
| 53 | Abs                | - |
| 54 | Floor              | - |