---
title: 数据增强综述
date: 2020-07-27 09:50:54
tags:
 - 深度学习
 - 数据增强
 - Data Augmentation
categories:
 - [deeplearning]
---

## 1、概述
很多实际的项目，我们都难以有充足的数据来完成任务，要保证完美的完成任务，有两件事情需要做好：

- 寻找更多的数据
- 数据增强（data augmentation）

**什么是数据增强**
数据增强也叫数据扩增，意思是在不实质性的增加数据的情况下，让有限的数据产生等价于更多数据的价值。

![](1.jpg)

数据增强可以分为**有监督的数据增强和无监督的数据增强方法**。其中有监督的数据增强又可以分为**单样本数据增强和多样本数据增强方法，无监督的数据增强分为生成新的数据和学习增强策略两个方向**。

## 2、有监督的数据增强
有监督数据增强，即**采用预设的数据变换规则，在已有数据的基础上进行数据的扩增**，包含单样本数据增强和多样本数据增强。

### 2.1、单样本数据增强
单样本数据增强，即增强一个样本的时候，全部围绕着该样本本身进行操作，包括**几何变换类，颜色变换类等**。

#### 2.1.1、几何变换类
几何变换类即对图像进行几何变换，包括**翻转，旋转，裁剪，变形，缩放**等各类操作.

> **翻转**

翻转包括水平翻转和垂直翻转。

![](2.webp)

> **随机裁剪**

裁剪图片的感兴趣区域（ROI），通常在训练的时候，会采用随机裁剪的方法，下图为随机裁剪4次的效果。

![](3.webp)

> **随机旋转**

对图像做一定角度对旋转操作.

![](4.webp)

> **缩放变形**

随机选取图像的一部分，然后将其缩放到原图像尺度。

![](5.webp)

翻转操作和旋转操作，对于那些对方向不敏感的任务，比如图像分类，都是很常见的操作，在caffe等框架中翻转对应的就是mirror操作。

翻转和旋转不改变图像的大小，而裁剪会改变图像的大小。通常在训练的时候会采用随机裁剪的方法，在测试的时候选择裁剪中间部分或者不裁剪。值得注意的是，在一些竞赛中进行模型测试时，一般都是裁剪输入的多个版本然后将结果进行融合，对预测的改进效果非常明显。

以上操作都不会产生失真，而缩放变形则是失真的。

很多的时候，网络的训练输入大小是固定的，但是数据集中的图像却大小不一，此时就可以选择上面的裁剪成固定大小输入或者缩放到网络的输入大小的方案，后者就会产生失真，通常效果比前者差。

> **仿射变换(Affine Transformation)**

同时对图片做裁剪、旋转、转换、模式调整等多重操作。

Affine Transformation是一种二维坐标到二维坐标之间的线性变换，保持二维图形的“平直性”（译注：straightness，即变换后直线还是直线不会打弯，圆弧还是圆弧）和“平行性”（译注：parallelness，其实是指保二维图形间的相对位置关系不变，平行线还是平行线，相交直线的交角不变。）

![](7.png)

仿射变换可以通过一系列的原子变换的复合来实现，包括：平移（Translation）、缩放（Scale）、翻转（Flip）、旋转（Rotation）和剪切（Shear）。

![](6.webp)

> **透视变换**

透视变换（Perspective Transformation）的本质是将图像投影到一个新的视平面，也称作投影映射。它是二维（x,y）到三维(X,Y,Z)，再到另一个二维(x’,y’)空间的映射。

仿射变换后平行四边形的各边仍操持平行，透视变换结果允许是梯形等四边形，所以仿射变换是透视变换的子集。

对图像应用一个随机的四点透视变换。

![](8.webp)

#### 2.1.2、颜色变换类
上面的几何变换类操作，没有改变图像本身的内容，它可能是选择了图像的一部分或者对像素进行了重分布。如果要改变图像本身的内容，就属于颜色变换类的数据增强了，常见的包括**噪声、模糊、颜色变换、擦除、填充**等等。

基于噪声的数据增强就是在原来的图片的基础上，随机叠加一些噪声，最常见的做法就是**高斯噪声**。更复杂一点的就是在面积大小可选定、位置随机的矩形区域上丢弃像素产生黑色矩形块，从而产生一些彩色噪声，以Coarse Dropout方法为代表，甚至还可以对图片上随机选取一块区域并擦除图像信息。

**噪声类：**

> **高斯噪声**

高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。如果一个噪声，它的幅度分布服从高斯分布，而它的功率谱密度又是均匀分布的，则称它为高斯白噪声。高斯白噪声的二阶矩不相关，一阶矩为常数，是指先后信号在时间上的相关性。

概率密度函数:

![](10.png)

σ为z的标准差,z为均值

![](9.webp)

> **椒盐噪声**

椒盐噪声是根据图像的信噪比,随机生成一些图像内的像素位置,并随机对这些像素点赋值为0或255。

概率密度函数:

![](11.png)

> **CoarseDropout**

在面积大小可选定、位置随机的矩形区域上丢失信息实现转换，所有通道的信息丢失产生黑色矩形块，部分通道的信息丢失产生彩色噪声。

![](12.webp)

> **SimplexNoiseAlpha**

产生连续单一噪声的掩模后，将掩模与原图像混合

![](13.webp)

> **FrequencyNoiseAlpha**

在频域中用随机指数对噪声映射进行加权，再转换到空间域。在不同图像中，随着指数值逐渐增大，依次出现平滑的大斑点、多云模式、重复出现的小斑块

![](14.webp)

**模糊类：**

减少各像素点值的差异实现图片模糊，实现像素的平滑化。

> **高斯模糊**

![](15.webp)

> **ElasticTransformation**

根据扭曲场的平滑度与强度逐一地移动局部像素点实现模糊效果。

![](16.webp)

> **HSV对比度变换**

通过向HSV空间中的每个像素添加或减少V值，修改色调和饱和度实现对比度转换。

![](17.webp)

> **RGB颜色扰动**

将图片从RGB颜色空间转换到另一颜色空间，增加或减少颜色参数后返回RGB颜色空间。

![](18.webp)

> **随机擦除法**

对图片上随机选取一块区域，随机地擦除图像信息。

![](19.webp)

> **超像素法（Superpixels）**

在最大分辨率处生成图像的若干个超像素，并将其调整到原始大小，再将原始图像中所有超像素区域按一定比例替换为超像素，其他区域不改变。

![](20.webp)

> **转换法（invert）**

按给定的概率值将部分或全部通道的像素值从v设置为255-v。

![](21.webp)

> **边界检测（EdgeDetect）**

检测图像中的所有边缘，将它们标记为黑白图像，再将结果与原始图像叠加。

![](22.webp)

> **GrayScale**

将图像从RGB颜色空间转换为灰度空间，通过某一通道与原图像混合。

![](23.webp)

> **锐化（sharpen）与浮雕（emboss）**

对图像执行某一程度的锐化或浮雕操作，通过某一通道将结果与图像融合。

下图分别是锐化与浮雕效果图:

![](24.webp)

### 2.2、多样本数据增强
不同于单样本数据增强，多样本数据增强方法利用多个样本来产生新的样本，下面介绍几种方法:

#### 2.2.1、SMOTE
SMOTE即Synthetic Minority Over-sampling Technique方法，它是通过人工合成新样本来处理样本不平衡问题，从而提升分类器性能。

类不平衡现象是很常见的，它指的是数据集中各类别数量不近似相等。如果样本类别之间相差很大，会影响分类器的分类效果。假设小样本数据数量极少，如仅占总体的1%，则即使小样本被错误地全部识别为大样本，在经验风险最小化策略下的分类器识别准确率仍能达到99%，但由于没有学习到小样本的特征，实际分类效果就会很差。

SMOTE方法是基于插值的方法，它可以为小样本类合成新的样本，主要流程为：

- 第一步，定义好特征空间，将每个样本对应到特征空间中的某一点，根据样本不平衡比例确定好一个采样倍率N；

- 第二步，对每一个小样本类样本(x,y)，按欧氏距离找出K个最近邻样本，从中随机选取一个样本点，假设选择的近邻点为(xn,yn)。在特征空间中样本点与最近邻样本点的连线段上随机选取一点作为新样本点，满足以下公式：

![](25.jpg)

- 第三步，重复以上的步骤，直到大、小样本数量平衡。

在python中，SMOTE算法已经封装到了imbalanced-learn库中，如下图为算法实现的数据增强的实例，左图为原始数据特征空间图，右图为SMOTE算法处理后的特征空间图:

![](26.webp)

#### 2.2.2、SamplePairing
SamplePairing方法的原理非常简单，从训练集中随机抽取两张图片分别经过基础数据增强操作(如随机翻转等)处理后经像素以取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。这两张图片甚至不限制为同一类别，这种方法对于医学图像比较有效。

![](27.webp)

训练过程是交替禁用与使用SamplePairing处理操作的结合：

- 使用传统的数据增强训练网络，不使用SamplePairing 数据增强训练。

- 在ILSVRC数据集上完成一个epoch或在其他数据集上完成100个epoch后，加入SamplePairing 数据增强训练。

- 间歇性禁用 SamplePairing。对于 ILSVRC 数据集，为其中的300000 个图像启用SamplePairing，然后在接下来的100000个图像中禁用它。对于其他数据集，在开始的8个epoch中启用，在接下来的2个epoch中禁止。

- 在训练损失函数和精度稳定后进行微调，禁用SamplePairing。

经SamplePairing处理后可使训练集的规模从N扩增到N×N。实验结果表明，因SamplePairing数据增强操作可能引入不同标签的训练样本，导致在各数据集上使用SamplePairing训练的误差明显增加，而在验证集上误差则有较大幅度降低。

尽管SamplePairing思路简单，性能上提升效果可观，符合奥卡姆剃刀原理，但遗憾的是可解释性不强。

#### 2.2.3、mixup
mixup是Facebook人工智能研究院和MIT在“Beyond Empirical Risk Minimization”中提出的基于邻域风险最小化原则的数据增强方法，它使用线性插值得到新样本数据。

令(xn,yn)是插值生成的新数据，(xi,yi)和(xj,yj)是训练集随机选取的两个数据，则数据生成方式如下:

![](28.jpg)

λ的取指范围介于0到1。提出mixup方法的作者们做了丰富的实验，实验结果表明可以改进深度学习模型在ImageNet数据集、CIFAR数据集、语音数据集和表格数据集中的泛化误差，降低模型对已损坏标签的记忆，增强模型对对抗样本的鲁棒性和训练生成对抗网络的稳定性。

**SMOTE，SamplePairing，mixup三者思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布**，不过所增加的样本点在特征空间中仍位于已知小样本点所围成的区域内。如果能够在给定范围之外适当插值，也许能实现更好的数据增强效果。

## 3、无监督的数据增强
无监督的数据增强方法包括两类：

- 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法GAN
- 通过模型，学习出适合当前任务的数据增强方法，代表方法AutoAugment

### 3.1、GAN
关于GAN(generative adversarial networks)，它包含两个网络，一个是生成网络，一个是对抗网络，基本原理如下：

- G是一个生成图片的网络，它接收随机的噪声z，通过噪声生成图片，记做G(z) 。
- D是一个判别网络，判别一张图片是不是“真实的”，即是真实的图片，还是由G生成的图片。

### 3.2、Autoaugmentation
AutoAugment是Google提出的自动选择最优数据增强方案的研究，这是无监督数据增强的重要研究方向。它的基本思路是使用增强学习从数据本身寻找最佳图像变换策略，对于不同的任务学习不同的增强方法。

## 4、参考代码
```
train_parameters = {
    "input_size": [3, 224, 224],
    "image_enhance_strategy": {  # 图像增强相关策略
        "need_distort": True,  # 是否启用图像颜色增强
        "need_rotate": True,   # 是否需要增加随机角度
        "need_crop": True,      # 是否要增加裁剪
        "need_flip": True,      # 是否要增加水平随机翻转
        "hue_prob": 0.5,
        "hue_delta": 18,
        "contrast_prob": 0.5,
        "contrast_delta": 0.5,
        "saturation_prob": 0.5,
        "saturation_delta": 0.5,
        "brightness_prob": 0.5,
        "brightness_delta": 0.125
    }
}
```

```
# 数据处理
def resize_img(img, target_size):
    """
    强制缩放图片
    :param img:
    :param target_size:
    :return:
    """
    target_size = input_size
    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)
    return img


def random_crop(img, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]):
    aspect_ratio = math.sqrt(np.random.uniform(*ratio))
    w = 1. * aspect_ratio
    h = 1. / aspect_ratio

    bound = min((float(img.size[0]) / img.size[1]) / (w**2),
                (float(img.size[1]) / img.size[0]) / (h**2))
    scale_max = min(scale[1], bound)
    scale_min = min(scale[0], bound)

    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min,
                                                                scale_max)
    target_size = math.sqrt(target_area)
    w = int(target_size * w)
    h = int(target_size * h)

    i = np.random.randint(0, img.size[0] - w + 1)
    j = np.random.randint(0, img.size[1] - h + 1)

    img = img.crop((i, j, i + w, j + h))
    img = img.resize((train_parameters['input_size'][1], train_parameters['input_size'][2]), Image.BILINEAR)
    return img


def rotate_image(img):
    """
    图像增强，增加随机旋转角度
    """
    angle = np.random.randint(-14, 15)
    img = img.rotate(angle)
    return img


def random_brightness(img):
    """
    图像增强，亮度调整
    :param img:
    :return:
    """
    prob = np.random.uniform(0, 1)
    if prob < train_parameters['image_enhance_strategy']['brightness_prob']:
        brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta']
        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1
        img = ImageEnhance.Brightness(img).enhance(delta)
    return img


def random_contrast(img):
    """
    图像增强，对比度调整
    :param img:
    :return:
    """
    prob = np.random.uniform(0, 1)
    if prob < train_parameters['image_enhance_strategy']['contrast_prob']:
        contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta']
        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1
        img = ImageEnhance.Contrast(img).enhance(delta)
    return img


def random_saturation(img):
    """
    图像增强，饱和度调整
    :param img:
    :return:
    """
    prob = np.random.uniform(0, 1)
    if prob < train_parameters['image_enhance_strategy']['saturation_prob']:
        saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta']
        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1
        img = ImageEnhance.Color(img).enhance(delta)
    return img


def random_hue(img):
    """
    图像增强，色度调整
    :param img:
    :return:
    """
    prob = np.random.uniform(0, 1)
    if prob < train_parameters['image_enhance_strategy']['hue_prob']:
        hue_delta = train_parameters['image_enhance_strategy']['hue_delta']
        delta = np.random.uniform(-hue_delta, hue_delta)
        img_hsv = np.array(img.convert('HSV'))
        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta
        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')
    return img


def distort_color(img):
    """
    概率的图像增强
    :param img:
    :return:
    """
    prob = np.random.uniform(0, 1)
    # Apply different distort order
    if prob < 0.35:
        img = random_brightness(img)
        img = random_contrast(img)
        img = random_saturation(img)
        img = random_hue(img)
    elif prob < 0.7:
        img = random_brightness(img)
        img = random_saturation(img)
        img = random_hue(img)
        img = random_contrast(img)
    return img
```